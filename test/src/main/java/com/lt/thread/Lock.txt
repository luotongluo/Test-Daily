    1，偏向锁：如果第一个线程获得了锁，则进行入偏向模式，如果接下来没有其他线程获取，则持有偏向锁的线程将不需要再进行同步。节省了申请所、释放锁，大大提高执行效率。如果锁竞争激烈的话，偏向锁将失效，还不如不用。可以通过-XX:+UseBiasedLocking进行控制开关。

       2，轻量级锁：将资源对象头部作为指针，指向持有锁的线程堆栈内部，来判断一个线程是否持有对象锁，如果线程获得（CAS）轻量级锁成功，则可以顺利进入同步块继续执行，否则轻量级锁失败，膨胀为重量级锁。  其提升程序同步性能的依据是：对于绝大部分的锁，在整个同步周期内都是不存在竞争的（前人经验数据）。

       3，自旋锁：偏向锁和轻量级锁都失败了，JVM还不会立刻挂起此线程，JVM认为很快就可以得到锁，于是会做若干个空循环（自旋）来重新获取锁，如果获取锁成功，则进入同步块执行，否则，才会将其挂起。

       4，锁消除：JVM在编译时，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁。我们在利用JDK一些类的时候，自己没有加锁，但是内部实现使用锁，而程序又不会出现并发安全问题，这时JVM就会帮我们进行锁消除，提高性能。
————————————————
版权声明：本文为CSDN博主「~小龙~」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/liujiahan629629/article/details/84844776

CAS——乐观锁：悲观锁VS乐观锁，比较好理解，不再赘述。看下JDK通过CAS（Compare and swap）乐观锁实现的一些类。JDK的atomic包提供了一些直接使用CAS操作的线程安全的类
AtomicInteger，通过CAS实现的一个线程安全的Integer，类似的还有AtomicBoolean、AtomicLong等。

  1，减小锁持有时间：锁持有时间越长，相对的锁竞争程度也就也激烈。方法就是在我们编码时，只在必要的代码段进行同步，没有线程安全的代码，则不要进行锁。这样有助于降低锁冲突的可能性，进而提升系统的并发能力。

       2，减小锁粒度：字面意思就是如何锁更小的资源。最典型的例子就是HashTable和ConcurrentHashMap，前者是锁住了整个对象，而后者只是锁住其中的要处理的Segment段（因为真正并发处理的这个Segment）。好比，人吃饭的，还可以看电视（锁住的是嘴，吃饭的时候不能喝茶，而不是整个人）。这里看下这个 HashMap、HashTable和ConcurrentHashMap的文章（http://www.cnblogs.com/-new/p/7496323.html）不了解的可以看下，更深刻理解JDK是如何高效的利用锁的。

      3，读写锁替换独占锁：在读多写少的情况下，使用ReadWriteLock可以大大提高程序执行效率。相对容易理解不再赘述。

      4，锁分离：读写锁分离了读操作和写操作，我们在进一步想，将更多的操作进行锁资源分离，就锁分离。典型的例子：LinkedBlockingQueue的实现，里边的take()和put()，虽然都操作整个队列进行修改数据，但是分别操作的队首和队尾，所以理论上是不冲突的。
5，锁粗化：前边我们说了：减少锁持有时间、减小锁粒度。这里怎么又有锁粗化了。前者是从锁占有时间和范围的角度去考虑，这里我们从锁的请求、同步、释放的频率进行考虑，如果频率过高也会消耗系统的宝贵资源。典型场景：对于需要锁的资源在循环当中，我们可以直接将锁粗化到循环外层，而不是在内层（避免每次循环都申请锁、释放锁的操作）。
————————————————
版权声明：本文为CSDN博主「~小龙~」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。
原文链接：https://blog.csdn.net/liujiahan629629/article/details/84844776